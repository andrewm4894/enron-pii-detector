{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls in from the training data and randomly samples some messages to be sent to the OpenAI API. \n",
    "\n",
    "The API will then return a response, which is then saved to `/data/labels_llm/{tag}/` as llm generated labels for later evaluation with by comparison to the ground truth human labels that live in `./data/labels/`.\n",
    "\n",
    "The approach here is to use minimal prompt engineering and make use of OpenAI function calling to get back structured data similar to what is generated by the labeling app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "from src.utils import clean_file_id, clean_message\n",
    "from src.openai import get_tools\n",
    "from src.utils import get_files\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def make_prompt(text):\n",
    "    \"\"\"Helper function to make the prompt for OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    perform PII entity extraction from the below email message(s) using the provided `extract_pii_entities` function.\n",
    "    \n",
    "    do not make up any entities or parts of entities that are not present in the message(s).\n",
    "\n",
    "    message(s):\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# \"tag\" is like an experiment id - it's used to keep track of different experiments/models/approaches etc\n",
    "params = {\n",
    "    \"tag\": \"dev\",\n",
    "    \"openai_model\": \"gpt-3.5-turbo\",\n",
    "    \"data_path\": \"./data/emails_train_small.csv\",\n",
    "}\n",
    "params[\"output_dir\"] = f\"./data/labels_llm/{params['tag']}\"\n",
    "params[\"nrows\"] = None\n",
    "\n",
    "# make output dir if it doesn't exist\n",
    "if not os.path.exists(params[\"output_dir\"]):\n",
    "    os.makedirs(params[\"output_dir\"])\n",
    "\n",
    "# save params\n",
    "with open(f\"{params['output_dir']}/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "    \n",
    "# save prompt\n",
    "with open(f\"{params['output_dir']}/prompt.txt\", \"w\") as f:\n",
    "    f.write(make_prompt(\"<text>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv(params['data_path'], nrows=params['nrows'])\n",
    "df['file_id_clean'] = df['file'].apply(clean_file_id)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>file_id_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany-c/calp_hopewell/4.</td>\n",
       "      <td>Message-ID: &lt;17014999.1075853725448.JavaMail.e...</td>\n",
       "      <td>germany_c_calp_hopewell_4_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campbell-l/all_documents/247.</td>\n",
       "      <td>Message-ID: &lt;23887281.1075851883486.JavaMail.e...</td>\n",
       "      <td>campbell_l_all_documents_247_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kitchen-l/_americas/mrha/ooc/270.</td>\n",
       "      <td>Message-ID: &lt;3290028.1075840876828.JavaMail.ev...</td>\n",
       "      <td>kitchen_l__americas_mrha_ooc_270_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zufferli-j/sent_items/124.</td>\n",
       "      <td>Message-ID: &lt;7771939.1075842030615.JavaMail.ev...</td>\n",
       "      <td>zufferli_j_sent_items_124_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokay-m/all_documents/906.</td>\n",
       "      <td>Message-ID: &lt;19991611.1075844044421.JavaMail.e...</td>\n",
       "      <td>lokay_m_all_documents_906_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  \\\n",
       "0         germany-c/calp_hopewell/4.   \n",
       "1      campbell-l/all_documents/247.   \n",
       "2  kitchen-l/_americas/mrha/ooc/270.   \n",
       "3         zufferli-j/sent_items/124.   \n",
       "4         lokay-m/all_documents/906.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <17014999.1075853725448.JavaMail.e...   \n",
       "1  Message-ID: <23887281.1075851883486.JavaMail.e...   \n",
       "2  Message-ID: <3290028.1075840876828.JavaMail.ev...   \n",
       "3  Message-ID: <7771939.1075842030615.JavaMail.ev...   \n",
       "4  Message-ID: <19991611.1075844044421.JavaMail.e...   \n",
       "\n",
       "                       file_id_clean  \n",
       "0         germany_c_calp_hopewell_4_  \n",
       "1      campbell_l_all_documents_247_  \n",
       "2  kitchen_l__americas_mrha_ooc_270_  \n",
       "3         zufferli_j_sent_items_124_  \n",
       "4         lokay_m_all_documents_906_  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files labeled: 74\n",
      "files labeled llm: 99\n",
      "files to process: 1\n"
     ]
    }
   ],
   "source": [
    "# find labeled data that hasn't been processed yet\n",
    "files_labels = get_files(f\"./data/labels/\")\n",
    "files_labels = [f.split('/')[-1].replace('.json','') for f in files_labels]\n",
    "print(f\"files labeled: {len(files_labels)}\")\n",
    "files_labels_llm = get_files(f\"{params['output_dir']}/\")\n",
    "files_labels_llm = [f.split('/')[-1].replace(f\"__{params['tag']}.json\",'') for f in files_labels_llm]\n",
    "print(f\"files labeled llm: {len(files_labels_llm)}\")\n",
    "files_to_process = list(set(files_labels) - set(files_labels_llm))\n",
    "# only process files that are in the df\n",
    "files_to_process = list(set(files_to_process) & set(df['file_id_clean'].unique()))\n",
    "print(f\"files to process: {len(files_to_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ring_r_eesirenewableenergy_55_\n",
      "====================================================================================================\n",
      "ring-r/eesirenewableenergy/55.\n",
      "ring_r_eesirenewableenergy_55_\n",
      "....................................................................................................\n",
      "Lamar:\n",
      "\n",
      "Fetzer spends about $700,000 per year on electricity.\n",
      "\n",
      "Natural Gas is negligble about 100,000 therms annually.\n",
      "\n",
      "Fetzer is an organic farm and winery.\n",
      "\n",
      "> -----Original Message-----\n",
      "> From:\tFrazier,Lamar \n",
      "> Sent:\tSunday, September 30, 2001 7:19 PM\n",
      "> To:\tKlemm, Aaron\n",
      "> Cc:\tRiley, Tom; richard.ring@enron.com\n",
      "> Subject:\tRe: Fetzer Vineyards and renewable power\n",
      "> \n",
      "> \n",
      "> \tAaron,\n",
      "> \n",
      "> \tCould you provide me with the monthly spend for both gas and\n",
      "> electric on this account.  I am assuming you have the gas spend.  We will\n",
      "> make a determination from there.  \n",
      "> \n",
      "> \tDick ,\n",
      "> \n",
      "> \tI know you have been trying to reach me about the other renewable\n",
      "> opportunity we discussed a couple of weeks ago, however, I just don't have\n",
      "> the resources at this time to work that opportunity.  Please feel free to\n",
      "> work the opportunity with your contact in Portland.  I apologize for the\n",
      "> delayed response. \n",
      "> \n",
      "> \tAaron please get back to me with whatever information you may have\n",
      "> on Fetzer.\n",
      "> \n",
      "> \tRegards,\n",
      "> \n",
      "> \tLamar\n",
      "> \n",
      "> \n",
      "> \n",
      "> \tFrom:\tAaron Klemm/Western Region/The Bentley Company@Exchange on\n",
      "> 09/27/2001 05:30 PM\n",
      "> \tTo:\tLamar Frazier/HOU/EES@EES\n",
      "> \tcc:\tTom Riley/Western Region/The Bentley Company@Exchange,\n",
      "> richard.ring@enron.com@SMTP@Exchange \n",
      "> \tSubject:\tFetzer Vineyards and renewable power\n",
      "> \n",
      "> \tRichard and Lamar:\n",
      "> \n",
      "> \tFetzer e-mailed me recently and wants to begin discussions on\n",
      "> extending their fixed price renewable power deal with us.\n",
      "> \n",
      "> \tTheir current fixed price expires in 5/02 with and index price going\n",
      "> out to 2009.\n",
      "> \n",
      "> \tIf this is below your radar, Lamar I would be happy to work it with\n",
      "> the customer and Richard on the renewable energy side.\n",
      "> \n",
      "> \tAaron Klemm\n",
      "> \tService Management\n",
      "> \t714-429-8125\n",
      "> \t714-434-7075\n",
      "> \n",
      "> \n",
      "> \n",
      "> \n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'email_addresses': ['richard.ring@enron.com'],\n",
      " 'names': ['Lamar',\n",
      "           'Frazier',\n",
      "           'Aaron',\n",
      "           'Klemm',\n",
      "           'Tom',\n",
      "           'Riley',\n",
      "           'Richard',\n",
      "           'Ring'],\n",
      " 'physical_addresses': ['Portland']}\n"
     ]
    }
   ],
   "source": [
    "# random sample from files to process\n",
    "file_to_process = np.random.choice(files_to_process, size=1, replace=False)[0]\n",
    "print(file_to_process)\n",
    "df_sample = df[df['file_id_clean'] == file_to_process]\n",
    "\n",
    "# sample a random message\n",
    "# df_sample = df.sample(1)\n",
    "\n",
    "# some data wrangling\n",
    "file_id = df_sample.file.values[0]\n",
    "file_id_clean = clean_file_id(file_id)\n",
    "text = df_sample.message.values[0]\n",
    "text_clean = clean_message(text)\n",
    "\n",
    "# print what we have\n",
    "print(\"=\" * 100)\n",
    "print(file_id)\n",
    "print(file_id_clean)\n",
    "print(\".\" * 100)\n",
    "print(text_clean)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# call openai\n",
    "prompt = make_prompt(text_clean)\n",
    "tools = get_tools()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=params['openai_model'],\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_pii_entities\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "# extract response\n",
    "chat_completion_message = chat_completion.choices[0].message\n",
    "tool_call = chat_completion_message.tool_calls[0]\n",
    "extracted_data = json.loads(tool_call.function.arguments)\n",
    "\n",
    "# print response\n",
    "pp.pprint(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./data/labels_llm/dev/ring_r_eesirenewableenergy_55___dev.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# save llm extracted data in ./data/labels_llm/{tag}/{file_id_clean}__{tag}.json\n",
    "output_path = f\"{params['output_dir']}/{file_id_clean}__{params['tag']}.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "print(f\"Saving to {output_path}\")\n",
    "extracted_data[\"file_id\"] = file_id\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(extracted_data, f)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
