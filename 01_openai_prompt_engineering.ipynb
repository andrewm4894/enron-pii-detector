{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls in from the training data and randomly samples some messages to be sent to the OpenAI API. \n",
    "\n",
    "The API will then return a response, which is then saved to `/data/labels_llm/{tag}/` as llm generated labels for later evaluation with by comparison to the ground truth human labels that live in `./data/labels/`.\n",
    "\n",
    "The approach here is to use minimal prompt engineering and make use of OpenAI function calling to get back structured data similar to what is generated by the labeling app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "from src.utils import clean_file_id, clean_message\n",
    "from src.openai import get_tools\n",
    "from src.utils import get_files\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def make_prompt(text):\n",
    "    \"\"\"Helper function to make the prompt for OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    perform PII entity extraction from the below email message(s) using the provided `extract_pii_entities` function.\n",
    "    \n",
    "    do not make up any entities or parts of entities that are not present in the message(s).\n",
    "\n",
    "    message(s):\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# \"tag\" is like an experiment id - it's used to keep track of different experiments/models/approaches etc\n",
    "params = {\n",
    "    \"tag\": \"dev_gpt4_1106_preview\",\n",
    "    \"openai_model\": \"gpt-4-1106-preview\",\n",
    "    \"data_path\": \"./data/emails_train_small.csv\",\n",
    "}\n",
    "params[\"output_dir\"] = f\"./data/labels_llm/{params['tag']}\"\n",
    "params[\"nrows\"] = None\n",
    "\n",
    "# make output dir if it doesn't exist\n",
    "if not os.path.exists(params[\"output_dir\"]):\n",
    "    os.makedirs(params[\"output_dir\"])\n",
    "\n",
    "# save params\n",
    "with open(f\"{params['output_dir']}/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "    \n",
    "# save prompt\n",
    "with open(f\"{params['output_dir']}/prompt.txt\", \"w\") as f:\n",
    "    f.write(make_prompt(\"<text>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv(params['data_path'], nrows=params['nrows'])\n",
    "df['file_id_clean'] = df['file'].apply(clean_file_id)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>file_id_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany-c/calp_hopewell/4.</td>\n",
       "      <td>Message-ID: &lt;17014999.1075853725448.JavaMail.e...</td>\n",
       "      <td>germany_c_calp_hopewell_4_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campbell-l/all_documents/247.</td>\n",
       "      <td>Message-ID: &lt;23887281.1075851883486.JavaMail.e...</td>\n",
       "      <td>campbell_l_all_documents_247_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kitchen-l/_americas/mrha/ooc/270.</td>\n",
       "      <td>Message-ID: &lt;3290028.1075840876828.JavaMail.ev...</td>\n",
       "      <td>kitchen_l__americas_mrha_ooc_270_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zufferli-j/sent_items/124.</td>\n",
       "      <td>Message-ID: &lt;7771939.1075842030615.JavaMail.ev...</td>\n",
       "      <td>zufferli_j_sent_items_124_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokay-m/all_documents/906.</td>\n",
       "      <td>Message-ID: &lt;19991611.1075844044421.JavaMail.e...</td>\n",
       "      <td>lokay_m_all_documents_906_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  \\\n",
       "0         germany-c/calp_hopewell/4.   \n",
       "1      campbell-l/all_documents/247.   \n",
       "2  kitchen-l/_americas/mrha/ooc/270.   \n",
       "3         zufferli-j/sent_items/124.   \n",
       "4         lokay-m/all_documents/906.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <17014999.1075853725448.JavaMail.e...   \n",
       "1  Message-ID: <23887281.1075851883486.JavaMail.e...   \n",
       "2  Message-ID: <3290028.1075840876828.JavaMail.ev...   \n",
       "3  Message-ID: <7771939.1075842030615.JavaMail.ev...   \n",
       "4  Message-ID: <19991611.1075844044421.JavaMail.e...   \n",
       "\n",
       "                       file_id_clean  \n",
       "0         germany_c_calp_hopewell_4_  \n",
       "1      campbell_l_all_documents_247_  \n",
       "2  kitchen_l__americas_mrha_ooc_270_  \n",
       "3         zufferli_j_sent_items_124_  \n",
       "4         lokay_m_all_documents_906_  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files labeled: 75\n",
      "files labeled llm: 56\n",
      "files to process: 1\n"
     ]
    }
   ],
   "source": [
    "# find labeled data that hasn't been processed yet\n",
    "files_labels = get_files(f\"./data/labels/\")\n",
    "files_labels = [f.split('/')[-1].replace('.json','') for f in files_labels]\n",
    "print(f\"files labeled: {len(files_labels)}\")\n",
    "files_labels_llm = get_files(f\"{params['output_dir']}/\")\n",
    "files_labels_llm = [f.split('/')[-1].replace(f\"__{params['tag']}.json\",'') for f in files_labels_llm]\n",
    "print(f\"files labeled llm: {len(files_labels_llm)}\")\n",
    "files_to_process = list(set(files_labels) - set(files_labels_llm))\n",
    "# only process files that are in the df\n",
    "files_to_process = list(set(files_to_process) & set(df['file_id_clean'].unique()))\n",
    "print(f\"files to process: {len(files_to_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mckay_b_deleted_items_289_\n",
      "====================================================================================================\n",
      "mckay-b/deleted_items/289.\n",
      "mckay_b_deleted_items_289_\n",
      "....................................................................................................\n",
      "Daily Market Commentary ATTENTION  . . . ATTENTION . . . ATTENTION . . . Beginning December 3 the Daily Briefs will be available only with a subscription to GasTrader Newsletter. With GasTrader Newsletter and the Daily Briefs not only will the short term outlook from the floor of the New York Mercantile Exchange be available, but the longer term outlook complete with no nonsense trading recommendations will be covered as well. Check out the website for a SAMPLE NEWSLETTER, sign up for a FREE 5 WEEK TRIAL SUBSCRIPTION at GasTrader.net or reply to this e-mail if interested in a special discount. . . . . .\n",
      "\n",
      "\n",
      "November 21, 2001\n",
      "\n",
      "NEED FOR COLD WEATHER CITED . . .\n",
      "\n",
      " Natural gas futures retreated in typically busy inventory report driven trading Wednesday on the New York Mercantile Exchange. Attentiion was focused of the release of the weekly AGA inventory figure which showed a\n",
      "moderately bearish 15 BCF build. Earlier expectations were from a draw of 10 BCF to a build of 10 BCF, and with working gas inventories brimming, traders thought the price decline should have been greater. Short term traders hypothesize a Monday collapse predictated on revised weather. . .\n",
      "\n",
      " At the closing bell the December futures slipped $.039 to $2.813 per MMBtu, and the January eased $.050 to $2.991 per MMBtu. . .\n",
      "\n",
      " \"I think that we come in on Monday with a revised 15 day forecast, and this\n",
      "market goes 30 cents south. At that point the market would be primed for a rally,\" said a New York floor trader. . .\n",
      "\n",
      " \"2.97 is a big (technical resistance) number, and traders find it hard to believe that the market will rally any more without an improvement in the\n",
      "fundamentals.\" . .\n",
      "\n",
      " \"I think what happens is thatthe market gets too short, it panics out and\n",
      "you have these rallies. (E.D.&F.) Man has done their best to goose the market\n",
      "higher. It's hard to figure out who is long at this point. . .\n",
      "\n",
      " The Man/Enron traders are still in the ring and they are executing orders\n",
      "for Enron, but their clearing relationship is over,\" he noted. . .\n",
      "\n",
      " Other traders see a need for some quick cold weather. . .\n",
      "\n",
      " \"I'm surprised the market didn't react more negatively to the AGA number,\"\n",
      "said Phil Flynn, broker analyst with Alaron, Chicago. . .\n",
      "\n",
      " \"There is speculation that some of the support to the market is Enron related because they are dumping positions, and many traders are saying that\n",
      "the market could get hit hard on Monday. . .\n",
      "\n",
      " To move this market higher it would have to get real cold, real quick and last real long,\" he said.\n",
      "\n",
      "\n",
      "\n",
      "For the most complete information available subscribe to GasTrader at http://gastrader.net\n",
      "\n",
      "Bill Burson\n",
      "120 Summit Blvd.\n",
      "Englewood, Colorado 80110\n",
      "Tel (303) 761-7470 * Fax (303) 761-8662\n",
      "(To be removed from this list send email to burson@gastrader.net)\n",
      "====================================================================================================\n",
      "{'email_addresses': ['burson@gastrader.net'],\n",
      " 'names': ['Phil Flynn', 'Bill Burson'],\n",
      " 'physical_addresses': ['120 Summit Blvd., Englewood, Colorado 80110']}\n"
     ]
    }
   ],
   "source": [
    "# random sample from files to process\n",
    "file_to_process = np.random.choice(files_to_process, size=1, replace=False)[0]\n",
    "print(file_to_process)\n",
    "df_sample = df[df['file_id_clean'] == file_to_process]\n",
    "\n",
    "# sample a random message\n",
    "# df_sample = df.sample(1)\n",
    "\n",
    "# some data wrangling\n",
    "file_id = df_sample.file.values[0]\n",
    "file_id_clean = clean_file_id(file_id)\n",
    "text = df_sample.message.values[0]\n",
    "text_clean = clean_message(text)\n",
    "\n",
    "# print what we have\n",
    "print(\"=\" * 100)\n",
    "print(file_id)\n",
    "print(file_id_clean)\n",
    "print(\".\" * 100)\n",
    "print(text_clean)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# call openai\n",
    "prompt = make_prompt(text_clean)\n",
    "tools = get_tools()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=params['openai_model'],\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_pii_entities\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "# extract response\n",
    "chat_completion_message = chat_completion.choices[0].message\n",
    "tool_call = chat_completion_message.tool_calls[0]\n",
    "extracted_data = json.loads(tool_call.function.arguments)\n",
    "\n",
    "# print response\n",
    "pp.pprint(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./data/labels_llm/dev_gpt4_1106_preview/mckay_b_deleted_items_289___dev_gpt4_1106_preview.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# save llm extracted data in ./data/labels_llm/{tag}/{file_id_clean}__{tag}.json\n",
    "output_path = f\"{params['output_dir']}/{file_id_clean}__{params['tag']}.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "print(f\"Saving to {output_path}\")\n",
    "extracted_data[\"file_id\"] = file_id\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(extracted_data, f)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
