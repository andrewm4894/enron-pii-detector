{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls in from the training data and randomly samples some messages to be sent to the OpenAI API. \n",
    "\n",
    "The API will then return a response, which is then saved to `/data/labels_llm/{tag}/` as llm generated labels for later evaluation with by comparison to the ground truth human labels that live in `./data/labels/`.\n",
    "\n",
    "The approach here is to use minimal prompt engineering and make use of OpenAI function calling to get back structured data similar to what is generated by the labeling app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "from src.utils import clean_file_id, clean_message\n",
    "from src.openai import get_tools\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def make_prompt(text):\n",
    "    \"\"\"Helper function to make the prompt for OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    perform PII entity extraction from the below email message(s) using the provided `extract_pii_entities` function.\n",
    "    \n",
    "    do not make up any entities or parts of entities that are not present in the message(s).\n",
    "\n",
    "    message(s):\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# \"tag\" is like an experiment id - it's used to keep track of different experiments/models/approaches etc\n",
    "tag = \"dev\" # just using \"dev\" for now for initial work and baseline\n",
    "openai_model = \"gpt-3.5-turbo\" # start with more simple model as a lower bound for performance\n",
    "data_path = \"./data/emails_train_small.csv\"\n",
    "# nrows = 1000\n",
    "nrows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv(data_path, nrows=nrows)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany-c/calp_hopewell/4.</td>\n",
       "      <td>Message-ID: &lt;17014999.1075853725448.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campbell-l/all_documents/247.</td>\n",
       "      <td>Message-ID: &lt;23887281.1075851883486.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kitchen-l/_americas/mrha/ooc/270.</td>\n",
       "      <td>Message-ID: &lt;3290028.1075840876828.JavaMail.ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zufferli-j/sent_items/124.</td>\n",
       "      <td>Message-ID: &lt;7771939.1075842030615.JavaMail.ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokay-m/all_documents/906.</td>\n",
       "      <td>Message-ID: &lt;19991611.1075844044421.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  \\\n",
       "0         germany-c/calp_hopewell/4.   \n",
       "1      campbell-l/all_documents/247.   \n",
       "2  kitchen-l/_americas/mrha/ooc/270.   \n",
       "3         zufferli-j/sent_items/124.   \n",
       "4         lokay-m/all_documents/906.   \n",
       "\n",
       "                                             message  \n",
       "0  Message-ID: <17014999.1075853725448.JavaMail.e...  \n",
       "1  Message-ID: <23887281.1075851883486.JavaMail.e...  \n",
       "2  Message-ID: <3290028.1075840876828.JavaMail.ev...  \n",
       "3  Message-ID: <7771939.1075842030615.JavaMail.ev...  \n",
       "4  Message-ID: <19991611.1075844044421.JavaMail.e...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "derrick-j/deleted_items/148.\n",
      "derrick_j_deleted_items_148_\n",
      "....................................................................................................\n",
      "Janet just left me a voice mail and believes this is an ENA deal after all.  Barbara--you may want to get ahold of Janet to verify ownership on this one.  Please let this group know what the final answer is.  DF\n",
      "\n",
      " -----Original Message-----\n",
      "From: \tFossum, Drew  \n",
      "Sent:\tTuesday, October 23, 2001 3:44 PM\n",
      "To:\tSanders, Richard B.\n",
      "Cc:\t'James Derrick (Business Fax)'; Edison, Andrew; Gray, Barbara N.; Place, Janet\n",
      "Subject:\tCrescendo\n",
      "\n",
      "The Crescendo project is a Northern Border project, and the appropriate contact for Christopher Sullivan (the fellow that left Jim the voice mail) is probably Janet Place.  I've left Janet a voice mail with the contact information on Sullivan and asked her to get ahold of him regarding his letter on the helium issue.  In case you access email ahead of voice mail Janet, the guy is Chistopher Sullivan, Rocky Mountain Helium, 1-800-945-1547.  Thanks all.  DF\n",
      "====================================================================================================\n",
      "{'email_addresses': [],\n",
      " 'names': ['Janet',\n",
      "           'Barbara',\n",
      "           'Drew',\n",
      "           'Richard',\n",
      "           'James Derrick',\n",
      "           'Andrew',\n",
      "           'Janet Place',\n",
      "           'Christopher Sullivan'],\n",
      " 'phone_numbers': ['1-800-945-1547'],\n",
      " 'physical_addresses': []}\n"
     ]
    }
   ],
   "source": [
    "# sample a random message\n",
    "df_sample = df.sample(1)\n",
    "\n",
    "# some data wrangling\n",
    "file_id = df_sample.file.values[0]\n",
    "file_id_clean = clean_file_id(file_id)\n",
    "text = df_sample.message.values[0]\n",
    "text_clean = clean_message(text)\n",
    "\n",
    "# print what we have\n",
    "print(\"=\" * 100)\n",
    "print(file_id)\n",
    "print(file_id_clean)\n",
    "print(\".\" * 100)\n",
    "print(text_clean)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# call openai\n",
    "prompt = make_prompt(text_clean)\n",
    "tools = get_tools()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=openai_model,\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_pii_entities\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "# extract response\n",
    "chat_completion_message = chat_completion.choices[0].message\n",
    "tool_call = chat_completion_message.tool_calls[0]\n",
    "extracted_data = json.loads(tool_call.function.arguments)\n",
    "\n",
    "# print response\n",
    "pp.pprint(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./data/labels_llm/dev/derrick_j_deleted_items_148___dev.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# save llm extracted data in ./data/labels_llm/{tag}/{file_id_clean}__{tag}.json\n",
    "output_path = f\"./data/labels_llm/{tag}/{file_id_clean}__{tag}.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "print(f\"Saving to {output_path}\")\n",
    "extracted_data[\"file_id\"] = file_id\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(extracted_data, f)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
