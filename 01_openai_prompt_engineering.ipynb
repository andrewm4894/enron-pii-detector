{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls in from the training data and randomly samples some messages to be sent to the OpenAI API. \n",
    "\n",
    "The API will then return a response, which is then saved to `/data/labels_llm/{tag}/` as llm generated labels for later evaluation with by comparison to the ground truth human labels that live in `./data/labels/`.\n",
    "\n",
    "The approach here is to use minimal prompt engineering and make use of OpenAI function calling to get back structured data similar to what is generated by the labeling app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "from src.utils import clean_file_id, clean_message\n",
    "from src.openai import get_tools\n",
    "from src.utils import get_files\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def make_prompt(text):\n",
    "    \"\"\"Helper function to make the prompt for OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    perform PII entity extraction from the below email message(s) using the provided `extract_pii_entities` function.\n",
    "    \n",
    "    do not make up any entities or parts of entities that are not present in the message(s).\n",
    "\n",
    "    message(s):\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# \"tag\" is like an experiment id - it's used to keep track of different experiments/models/approaches etc\n",
    "params = {\n",
    "    \"tag\": \"dev_gpt4_1106_preview\",\n",
    "    \"openai_model\": \"gpt-4-1106-preview\",\n",
    "    \"data_path\": \"./data/emails_train_small.csv\",\n",
    "}\n",
    "params[\"output_dir\"] = f\"./data/labels_llm/{params['tag']}\"\n",
    "params[\"nrows\"] = None\n",
    "\n",
    "# make output dir if it doesn't exist\n",
    "if not os.path.exists(params[\"output_dir\"]):\n",
    "    os.makedirs(params[\"output_dir\"])\n",
    "\n",
    "# save params\n",
    "with open(f\"{params['output_dir']}/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)\n",
    "    \n",
    "# save prompt\n",
    "with open(f\"{params['output_dir']}/prompt.txt\", \"w\") as f:\n",
    "    f.write(make_prompt(\"<text>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv(params['data_path'], nrows=params['nrows'])\n",
    "df['file_id_clean'] = df['file'].apply(clean_file_id)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>file_id_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany-c/calp_hopewell/4.</td>\n",
       "      <td>Message-ID: &lt;17014999.1075853725448.JavaMail.e...</td>\n",
       "      <td>germany_c_calp_hopewell_4_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campbell-l/all_documents/247.</td>\n",
       "      <td>Message-ID: &lt;23887281.1075851883486.JavaMail.e...</td>\n",
       "      <td>campbell_l_all_documents_247_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kitchen-l/_americas/mrha/ooc/270.</td>\n",
       "      <td>Message-ID: &lt;3290028.1075840876828.JavaMail.ev...</td>\n",
       "      <td>kitchen_l__americas_mrha_ooc_270_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zufferli-j/sent_items/124.</td>\n",
       "      <td>Message-ID: &lt;7771939.1075842030615.JavaMail.ev...</td>\n",
       "      <td>zufferli_j_sent_items_124_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokay-m/all_documents/906.</td>\n",
       "      <td>Message-ID: &lt;19991611.1075844044421.JavaMail.e...</td>\n",
       "      <td>lokay_m_all_documents_906_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  \\\n",
       "0         germany-c/calp_hopewell/4.   \n",
       "1      campbell-l/all_documents/247.   \n",
       "2  kitchen-l/_americas/mrha/ooc/270.   \n",
       "3         zufferli-j/sent_items/124.   \n",
       "4         lokay-m/all_documents/906.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <17014999.1075853725448.JavaMail.e...   \n",
       "1  Message-ID: <23887281.1075851883486.JavaMail.e...   \n",
       "2  Message-ID: <3290028.1075840876828.JavaMail.ev...   \n",
       "3  Message-ID: <7771939.1075842030615.JavaMail.ev...   \n",
       "4  Message-ID: <19991611.1075844044421.JavaMail.e...   \n",
       "\n",
       "                       file_id_clean  \n",
       "0         germany_c_calp_hopewell_4_  \n",
       "1      campbell_l_all_documents_247_  \n",
       "2  kitchen_l__americas_mrha_ooc_270_  \n",
       "3         zufferli_j_sent_items_124_  \n",
       "4         lokay_m_all_documents_906_  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files labeled: 74\n",
      "files labeled llm: 19\n",
      "files to process: 36\n"
     ]
    }
   ],
   "source": [
    "# find labeled data that hasn't been processed yet\n",
    "files_labels = get_files(f\"./data/labels/\")\n",
    "files_labels = [f.split('/')[-1].replace('.json','') for f in files_labels]\n",
    "print(f\"files labeled: {len(files_labels)}\")\n",
    "files_labels_llm = get_files(f\"{params['output_dir']}/\")\n",
    "files_labels_llm = [f.split('/')[-1].replace(f\"__{params['tag']}.json\",'') for f in files_labels_llm]\n",
    "print(f\"files labeled llm: {len(files_labels_llm)}\")\n",
    "files_to_process = list(set(files_labels) - set(files_labels_llm))\n",
    "# only process files that are in the df\n",
    "files_to_process = list(set(files_to_process) & set(df['file_id_clean'].unique()))\n",
    "print(f\"files to process: {len(files_to_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guzman_m_all_documents_999_\n",
      "====================================================================================================\n",
      "guzman-m/all_documents/999.\n",
      "guzman_m_all_documents_999_\n",
      "....................................................................................................\n",
      "Start Date: 3/3/01; HourAhead hour: 5;  No ancillary schedules awarded.  No \n",
      "variances detected.\n",
      "\n",
      "    LOG MESSAGES:\n",
      "\n",
      "PARSING FILE -->> O:\\Portland\\WestDesk\\California Scheduling\\ISO Final \n",
      "Schedules\\2001030305.txt\n",
      "====================================================================================================\n",
      "{'physical_addresses': ['O:\\\\Portland\\\\WestDesk\\\\California Scheduling']}\n"
     ]
    }
   ],
   "source": [
    "# random sample from files to process\n",
    "file_to_process = np.random.choice(files_to_process, size=1, replace=False)[0]\n",
    "print(file_to_process)\n",
    "df_sample = df[df['file_id_clean'] == file_to_process]\n",
    "\n",
    "# sample a random message\n",
    "# df_sample = df.sample(1)\n",
    "\n",
    "# some data wrangling\n",
    "file_id = df_sample.file.values[0]\n",
    "file_id_clean = clean_file_id(file_id)\n",
    "text = df_sample.message.values[0]\n",
    "text_clean = clean_message(text)\n",
    "\n",
    "# print what we have\n",
    "print(\"=\" * 100)\n",
    "print(file_id)\n",
    "print(file_id_clean)\n",
    "print(\".\" * 100)\n",
    "print(text_clean)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# call openai\n",
    "prompt = make_prompt(text_clean)\n",
    "tools = get_tools()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=params['openai_model'],\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_pii_entities\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "# extract response\n",
    "chat_completion_message = chat_completion.choices[0].message\n",
    "tool_call = chat_completion_message.tool_calls[0]\n",
    "extracted_data = json.loads(tool_call.function.arguments)\n",
    "\n",
    "# print response\n",
    "pp.pprint(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./data/labels_llm/dev_gpt4_1106_preview/guzman_m_all_documents_999___dev_gpt4_1106_preview.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# save llm extracted data in ./data/labels_llm/{tag}/{file_id_clean}__{tag}.json\n",
    "output_path = f\"{params['output_dir']}/{file_id_clean}__{params['tag']}.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "print(f\"Saving to {output_path}\")\n",
    "extracted_data[\"file_id\"] = file_id\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(extracted_data, f)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
