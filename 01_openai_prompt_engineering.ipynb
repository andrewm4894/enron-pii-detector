{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pulls in from the training data and randomly samples some messages to be sent to the OpenAI API. \n",
    "\n",
    "The API will then return a response, which is then saved to `/data/labels_llm/{tag}/` as llm generated labels for later evaluation with by comparison to the ground truth human labels that live in `./data/labels/`.\n",
    "\n",
    "The approach here is to use minimal prompt engineering and make use of OpenAI function calling to get back structured data similar to what is generated by the labeling app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import pprint as pp\n",
    "from src.utils import clean_file_id, clean_message\n",
    "from src.openai import get_tools\n",
    "from src.utils import get_files\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def make_prompt(text):\n",
    "    \"\"\"Helper function to make the prompt for OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    perform PII entity extraction from the below email message(s) using the provided `extract_pii_entities` function.\n",
    "    \n",
    "    do not make up any entities or parts of entities that are not present in the message(s).\n",
    "\n",
    "    message(s):\n",
    "    ```\n",
    "    {text}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def make_prompt_few_shot(text, examples):\n",
    "    \"\"\"Helper function to make the prompt for OpenAI.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "perform PII entity extraction from the below email message(s) using the provided `extract_pii_entities` function.\n",
    "\n",
    "do not make up any entities or parts of entities that are not present in the message(s).\n",
    "\n",
    "here are some example messages followed by the entities that should be extracted from them.\n",
    "\n",
    "lastly there is a message that you should extract entities from.\n",
    "\n",
    "{examples}\n",
    "\n",
    "## MESSAGE:\n",
    "```\n",
    "{text}\n",
    "```\n",
    "\n",
    "## ENTITIES:\n",
    "\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "# \"tag\" is like an experiment id - it's used to keep track of different experiments/models/approaches etc\n",
    "params = {\n",
    "    \"tag\": \"dev_gpt4_1106_preview_few_shot_1\",\n",
    "    \"openai_model\": \"gpt-4-1106-preview\",\n",
    "    \"data_path\": \"./data/emails_train_small.csv\",\n",
    "    \"few_shot\": True,\n",
    "}\n",
    "params[\"output_dir\"] = f\"./data/labels_llm/{params['tag']}\"\n",
    "params[\"nrows\"] = None\n",
    "\n",
    "# make output dir if it doesn't exist\n",
    "if not os.path.exists(params[\"output_dir\"]):\n",
    "    os.makedirs(params[\"output_dir\"])\n",
    "\n",
    "# load data from ./data/few_shot_examples.txt\n",
    "if params[\"few_shot\"]==True:\n",
    "    with open(\"./data/few_shot_examples.txt\", \"r\") as f:\n",
    "        examples = f.read()\n",
    "    # save prompt\n",
    "    with open(f\"{params['output_dir']}/prompt.txt\", \"w\") as f:\n",
    "        f.write(make_prompt_few_shot(\"<text>\",examples=examples))\n",
    "else:\n",
    "    examples = None\n",
    "    # save prompt\n",
    "    with open(f\"{params['output_dir']}/prompt.txt\", \"w\") as f:\n",
    "        f.write(make_prompt(\"<text>\"))\n",
    "\n",
    "# save params\n",
    "with open(f\"{params['output_dir']}/params.json\", \"w\") as f:\n",
    "    json.dump(params, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv(params['data_path'], nrows=params['nrows'])\n",
    "df['file_id_clean'] = df['file'].apply(clean_file_id)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>message</th>\n",
       "      <th>file_id_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>germany-c/calp_hopewell/4.</td>\n",
       "      <td>Message-ID: &lt;17014999.1075853725448.JavaMail.e...</td>\n",
       "      <td>germany_c_calp_hopewell_4_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campbell-l/all_documents/247.</td>\n",
       "      <td>Message-ID: &lt;23887281.1075851883486.JavaMail.e...</td>\n",
       "      <td>campbell_l_all_documents_247_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kitchen-l/_americas/mrha/ooc/270.</td>\n",
       "      <td>Message-ID: &lt;3290028.1075840876828.JavaMail.ev...</td>\n",
       "      <td>kitchen_l__americas_mrha_ooc_270_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zufferli-j/sent_items/124.</td>\n",
       "      <td>Message-ID: &lt;7771939.1075842030615.JavaMail.ev...</td>\n",
       "      <td>zufferli_j_sent_items_124_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokay-m/all_documents/906.</td>\n",
       "      <td>Message-ID: &lt;19991611.1075844044421.JavaMail.e...</td>\n",
       "      <td>lokay_m_all_documents_906_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                file  \\\n",
       "0         germany-c/calp_hopewell/4.   \n",
       "1      campbell-l/all_documents/247.   \n",
       "2  kitchen-l/_americas/mrha/ooc/270.   \n",
       "3         zufferli-j/sent_items/124.   \n",
       "4         lokay-m/all_documents/906.   \n",
       "\n",
       "                                             message  \\\n",
       "0  Message-ID: <17014999.1075853725448.JavaMail.e...   \n",
       "1  Message-ID: <23887281.1075851883486.JavaMail.e...   \n",
       "2  Message-ID: <3290028.1075840876828.JavaMail.ev...   \n",
       "3  Message-ID: <7771939.1075842030615.JavaMail.ev...   \n",
       "4  Message-ID: <19991611.1075844044421.JavaMail.e...   \n",
       "\n",
       "                       file_id_clean  \n",
       "0         germany_c_calp_hopewell_4_  \n",
       "1      campbell_l_all_documents_247_  \n",
       "2  kitchen_l__americas_mrha_ooc_270_  \n",
       "3         zufferli_j_sent_items_124_  \n",
       "4         lokay_m_all_documents_906_  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files labeled: 81\n",
      "files labeled llm: 55\n",
      "files to process: 1\n"
     ]
    }
   ],
   "source": [
    "# find labeled data that hasn't been processed yet\n",
    "files_labels = get_files(f\"./data/labels/\")\n",
    "files_labels = [f.split('/')[-1].replace('.json','') for f in files_labels]\n",
    "print(f\"files labeled: {len(files_labels)}\")\n",
    "files_labels_llm = get_files(f\"{params['output_dir']}/\")\n",
    "files_labels_llm = [f.split('/')[-1].replace(f\"__{params['tag']}.json\",'') for f in files_labels_llm]\n",
    "print(f\"files labeled llm: {len(files_labels_llm)}\")\n",
    "files_to_process = list(set(files_labels) - set(files_labels_llm))\n",
    "# only process files that are in the df\n",
    "files_to_process = list(set(files_to_process) & set(df['file_id_clean'].unique()))\n",
    "print(f\"files to process: {len(files_to_process)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nemec_g_notes_inbox_1396_\n",
      "====================================================================================================\n",
      "nemec-g/notes_inbox/1396.\n",
      "nemec_g_notes_inbox_1396_\n",
      "....................................................................................................\n",
      "Please join Lexis-Nexis trainings specific tailored for legal.  Learn to=20\n",
      "conduct Lexis-Nexis search from Enron Lexis-Nexis web page on our portal. T=\n",
      "he=20\n",
      "training schedule now is posted on our portal Enron Legal Edge=20\n",
      "http://legaledge.corp.enron.com/  under Lexis Day Announcement banner and i=\n",
      "n=20\n",
      "the Legal Calendar.  Lexis-Nexis link is in Research category.\n",
      "\n",
      "Join Lexis-Nexis Day at Enron Legal Houston to\n",
      " discover LEXIS-NEXIS and it=01,s vast\n",
      " collection of information on=20\n",
      "All areas of Law and Business\n",
      "Watch as LEXIS-NEXIS SEARCH ADVISOR practically does all of your research f=\n",
      "or=20\n",
      "you.\n",
      "\n",
      "Tuesday, May 15, 2001\n",
      "Conference Room EB48C2\n",
      "\n",
      "9:00 am - 10:00 am- Lexis.com Basic\n",
      "10:30 am-11:30 am- e-Commerce & Cyberlaw\n",
      "Noon - 1:00 pm  - Area of Laws/Practice Pages=20\n",
      "1:30 pm- 2:30 pm- Public Records\n",
      "3:00 pm-4:00 pm - International Research=20\n",
      "\n",
      "\n",
      "Presenting by Ed Chang, Lexis Consulting Attorney\n",
      "Training sessions are free to Enron Legal Personnel\n",
      "Lunch will be provided by Lexis\n",
      "R.S.V.P. to Sylvia Hu ext. 36775 sylvia.hu@enron.com=20\n",
      "<mailto:sylvia.hu@enron.com> by Monday Noon\n",
      "====================================================================================================\n",
      "{'email_addresses': ['sylvia.hu@enron.com'],\n",
      " 'names': ['Sylvia Hu', 'Ed Chang'],\n",
      " 'phone_numbers': ['36775'],\n",
      " 'physical_addresses': ['Conference Room EB48C2']}\n"
     ]
    }
   ],
   "source": [
    "# random sample from files to process\n",
    "file_to_process = np.random.choice(files_to_process, size=1, replace=False)[0]\n",
    "print(file_to_process)\n",
    "df_sample = df[df['file_id_clean'] == file_to_process]\n",
    "\n",
    "# sample a random message\n",
    "# df_sample = df.sample(1)\n",
    "\n",
    "# some data wrangling\n",
    "file_id = df_sample.file.values[0]\n",
    "file_id_clean = clean_file_id(file_id)\n",
    "text = df_sample.message.values[0]\n",
    "text_clean = clean_message(text)\n",
    "\n",
    "# print what we have\n",
    "print(\"=\" * 100)\n",
    "print(file_id)\n",
    "print(file_id_clean)\n",
    "print(\".\" * 100)\n",
    "print(text_clean)\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# call openai\n",
    "if params['few_shot'] == True:\n",
    "    prompt = make_prompt_few_shot(text_clean, examples=examples)\n",
    "else:\n",
    "    prompt = make_prompt(text_clean)\n",
    "tools = get_tools()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    model=params['openai_model'],\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_pii_entities\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "# extract response\n",
    "chat_completion_message = chat_completion.choices[0].message\n",
    "tool_call = chat_completion_message.tool_calls[0]\n",
    "extracted_data = json.loads(tool_call.function.arguments)\n",
    "\n",
    "# print response\n",
    "pp.pprint(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./data/labels_llm/dev_gpt4_1106_preview_few_shot_1/nemec_g_notes_inbox_1396___dev_gpt4_1106_preview_few_shot_1.json\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# save llm extracted data in ./data/labels_llm/{tag}/{file_id_clean}__{tag}.json\n",
    "output_path = f\"{params['output_dir']}/{file_id_clean}__{params['tag']}.json\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "print(f\"Saving to {output_path}\")\n",
    "extracted_data[\"file_id\"] = file_id\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(extracted_data, f)\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
