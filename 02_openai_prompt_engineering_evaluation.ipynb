{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_files\n",
    "from src.eval import create_labels_dict, merge_labels, calculate_metrics, calculate_overall_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "tag = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_labels_llm = get_files(f\"./data/labels_llm/{tag}/\")\n",
    "files_labels = get_files(f\"./data/labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_llm = create_labels_dict(files_labels_llm, tag='dev')\n",
    "labels = create_labels_dict(files_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common labels: 28\n"
     ]
    }
   ],
   "source": [
    "labels_final = merge_labels(labels, labels_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "entity_metrics = calculate_metrics(labels_final)\n",
    "overall_metrics = calculate_overall_metrics(entity_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall Precision': 0.359504132231405,\n",
       " 'Overall Recall': 0.34523809523809523,\n",
       " 'Overall F1 Score': 0.3522267206477733}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function src.eval.calculate_metrics.<locals>.<lambda>()>,\n",
       "            {'names': {'TP': 82,\n",
       "              'FP': 94,\n",
       "              'FN': 59,\n",
       "              'Precision': 0.4659090909090909,\n",
       "              'Recall': 0.5815602836879432,\n",
       "              'F1 Score': 0.5173501577287066},\n",
       "             'phone_numbers': {'TP': 1,\n",
       "              'FP': 1,\n",
       "              'FN': 28,\n",
       "              'Precision': 0.5,\n",
       "              'Recall': 0.034482758620689655,\n",
       "              'F1 Score': 0.06451612903225806},\n",
       "             'email_addresses': {'TP': 4,\n",
       "              'FP': 59,\n",
       "              'FN': 50,\n",
       "              'Precision': 0.06349206349206349,\n",
       "              'Recall': 0.07407407407407407,\n",
       "              'F1 Score': 0.06837606837606837},\n",
       "             'physical_addresses': {'TP': 0,\n",
       "              'FP': 1,\n",
       "              'FN': 28,\n",
       "              'Precision': 0.0,\n",
       "              'Recall': 0.0,\n",
       "              'F1 Score': 0}})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
